{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 3\n",
    "\n",
    "\n",
    "#### Plotting more lines\n",
    "\n",
    "1. Repeat question 1 on worksheet 2 but add a polynomial fit line and a moving average line.\n",
    "Have a look at teh following for different ways of fitting a polynomial curve\n",
    "https://towardsdatascience.com/polynomial-regression-which-python-package-to-use-78a09b0ac87b\n",
    "It might be worth creating functions for each of the lines of fit and plotting serveral!\n",
    "\n",
    "\n",
    "\n",
    "#### Regression problem\n",
    "\n",
    "In this problem we'll try out a simple machine learning application. We will try and predict the \"feels like\" temperature from some other variables. Check out the \"bike sharing demand\" kaggle challenge for a similar application!\n",
    "\n",
    "1. Load in the train and test set, the training set is what the algorithm learns from and the test set is unseen data that we evaluate our model on. You'll need to separate the target variable from both datasets, that means you'll end up with 4 variables: test_X, test_y, train_X, train_y. The X variables will include temp, humidity and windspeed and the y variables will include atemp. What is the cross validation set?\n",
    "\n",
    "temp - temperature in Celsius\n",
    "atemp - \"feels like\" temperature in Celsius\n",
    "humidity - relative humidity\n",
    "windspeed - wind speed\n",
    "\n",
    "2. Now train a random forest regressor on the train data and evaluate it on the test data. Try printing the RMSE and make a plot of the two arrays. What do you notice? What happens if you remove features from the dataset? \n",
    "\n",
    "For clues on what to do, look at:\n",
    "https://towardsdatascience.com/random-forest-and-its-implementation-71824ced454f\n",
    "\n",
    "3. Extension 1: repeat the last step on a different model, try a gradient boosting model for example. Is this model better?\n",
    "https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n",
    "https://medium.com/fintechexplained/bagging-vs-boosting-in-machine-learning-8d7512d782e0\n",
    "\n",
    "4. Extension 2: Try the bike hsaring demand kaggle challenge! What happens when we start predicting variables that have more randomness in the system? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
