{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Working with ensemble data**\n",
    "\n",
    "To do this you will need to download \"HadSST.4.0.0.0_ensemble.zip\" from https://www.metoffice.gov.uk/hadobs/hadsst4/data/download.html it is a massive folder of 200 ensemble members! A useful tool for looking at netcdf files: Panoply (Nasa) https://www.giss.nasa.gov/tools/panoply/ \n",
    "\n",
    "1. Initialise any arrays\n",
    "\n",
    "2. Create a for loop which loops through the files in the ensemble foler and loads each sst file and the variables\n",
    "\n",
    "3. Within the for loop calculate the baseline, current climates and anomalies for each of the files\n",
    "uses formulas from last week \n",
    "\n",
    "4. For each type of climate: baselines, currents and anomalies, concatenate the arrays so you end up with three arrays of shape (200,36,72) (as you have 200 files, you will have 200 values for each grid point) \n",
    "data2 = pd.concat([year, anomaly], axis=1) # learned to concatenate two series into a df\n",
    "\n",
    "5. outside of the for loop calculate the anomaly mean (for each grid point)\n",
    "\n",
    "6. Now loop through all of the grid points and compare the distributions of the baseline compared to the currents - are they significantly different (i.e. is the global sst now significantly different from what it was during the baseline?)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "from netCDF4 import Dataset,num2date\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop through the files in the ensemble folder, and load each sst file and the variables, and calculate the baseline, current climates, and anomalies for each of the files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up variables (outside of loop)\n",
    "example = Dataset('/Users/bendixon/Documents/HadSST/HadSST.4.0.0.0_ensemble_member_1.nc')\n",
    "\n",
    "# time and lat and lon are global variables\n",
    "latitude = example.variables['latitude'][:]\n",
    "longitude = example.variables['longitude'][:]\n",
    "\n",
    "# time \n",
    "time = example.variables['time'][:]\n",
    "time_units = example.variables['time'].units\n",
    "calendar = example.variables['time'].calendar # I think Gregorian might be the default, not sure if needed\n",
    "time_convert = num2date(time, time_units, calendar)\n",
    "i_1950 = 1200; i_1980 = 1569; i_2000 = 1800; i_2018 = 2027    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(fn):\n",
    "    # Opening the file and loading the temperature value\n",
    "    swta = Dataset(fn).variables['tos'][:]\n",
    "    swta = np.ma.masked_values(swta, 9.969209968386869e+36)\n",
    "    # Setting the time parameters () \n",
    "    baseline = swta[i_1950:i_1980,:,:]\n",
    "    baseline = np.mean(baseline,axis=0) \n",
    "    return baseline # Returning the baseline value from the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current(fn):\n",
    "    # Opening the file and loading the temperature value\n",
    "    swta = Dataset(fn).variables['tos'][:]\n",
    "    swta = np.ma.masked_values(swta, 9.969209968386869e+36)\n",
    "    # Setting the time parameters () \n",
    "    current = swta[i_2000:i_2018,:,:]\n",
    "    current = np.mean(current,axis=0)\n",
    "    return current # Returning the baseline value from the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Potential improvements*\n",
    "\n",
    "* Merge baseline and current files to do mean(start_date,end_date) so no need for individual functions\n",
    "* Also work out how to go from start and end date in DD-MM-YYYY to the position in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 36, 72)\n",
      "(201, 36, 72)\n"
     ]
    }
   ],
   "source": [
    "# Initialise the arrays \n",
    "bas_a = np.zeros((1,36,72)) \n",
    "cur_a = np.zeros((1,36,72))\n",
    "\n",
    "directory = '/Users/bendixon/Documents/HadSST/'\n",
    "os.chdir('/Users/bendixon/Documents/HadSST/') # do we need to do both of these?\n",
    "# looping through the models, working out the baseline\n",
    "for filename in os.listdir(directory):\n",
    "    bas = np.array([baseline(filename)]) \n",
    "    bas_b = np.concatenate((bas,bas_a),axis=0)\n",
    "    bas_a = bas_b # Maybe there's a better way of doing this another loop\n",
    "print(bas_b.shape)\n",
    "# looping through the models, working out the current value\n",
    "for filename in os.listdir(directory):\n",
    "    cur = np.array([current(filename)])\n",
    "    cur_b = np.concatenate((cur,cur_a),axis=0)\n",
    "    cur_a = cur_b\n",
    "print(cur_b.shape)\n",
    "# Is there a better way using loops rather than setting cur_a = cur_b at the end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 36, 72)\n"
     ]
    }
   ],
   "source": [
    "anom_a = np.zeros((201,36,72))\n",
    "anom_a = np.subtract(cur_b,bas_b)\n",
    "print(anom_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are these values statistically significant?\n",
    "# Comparing \n",
    "statistic = []\n",
    "significance = [] # I tried this with a 36 by 72 array but couldnt get the loop to insert in the right places\n",
    "\n",
    "from scipy.stats import ks_2samp # Kolmogorov-Smirnov statistic on two samples\n",
    "\n",
    "for i in range(36):\n",
    "    m = []\n",
    "    for j in range(72):\n",
    "        s = ks_2samp(bas_b[:,i,j],cur_b[:,i,j]).statistic\n",
    "        s = float(s)\n",
    "        statistic.append(s)\n",
    "        p = ks_2samp(bas_b[:,i,j],cur_b[:,i,j]).pvalue\n",
    "        if p < 0.01:\n",
    "            significance.append(True)\n",
    "        else:\n",
    "            significance.append(False)\n",
    "        \n",
    "statistic = np.reshape(statistic,(36,72)) # putting this into a nice array \n",
    "significance = np.reshape(significance,(36,72)) # putting this into a nice array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workings/ideas - ignore the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bendixon/Documents/HadSST'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old function definition, in case needed later\n",
    "def anomaly(fn):\n",
    "    # Opening the file and loading the temperature value\n",
    "    swta_file = Dataset(fn)\n",
    "    variables = swta_file.variables\n",
    "    swta = swta_file.variables['tos'][:]\n",
    "    swta = np.ma.masked_values(swta, 9.969209968386869e+36)\n",
    "    # Setting the time parameters () \n",
    "    baseline = swta[i_1950:i_1980,:,:]\n",
    "    baseline = np.mean(baseline,axis=0) \n",
    "    current = swta[i_2000:i_2018,:,:]\n",
    "    current = np.mean(current,axis=0)\n",
    "    # Printing the anomaly\n",
    "    anom = current - baseline\n",
    "    anom = np.array(anom, dtype=float)\n",
    "    return anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950-01-16 12:00:00\n",
      "1980-01-16 12:00:00\n",
      "2000-01-16 12:00:00\n",
      "2018-12-16 12:00:00\n"
     ]
    }
   ],
   "source": [
    "print(time_convert[1200])\n",
    "print(time_convert[1560]) # not sure why some months there are measurements at 00:00 or 12:00\n",
    "print(time_convert[1800])\n",
    "print(time_convert[2027]) # this is only up to 2018, but that's the size of the array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
