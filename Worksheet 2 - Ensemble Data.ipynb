{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Working with ensemble data**\n",
    "\n",
    "To do this you will need to download \"HadSST.4.0.0.0_ensemble.zip\" from https://www.metoffice.gov.uk/hadobs/hadsst4/data/download.html it is a massive folder of 200 ensemble members! A useful tool for looking at netcdf files: Panoply (Nasa) https://www.giss.nasa.gov/tools/panoply/ \n",
    "\n",
    "Model ensembles are very common. They represent a group (anywhere between 2 and 100+) of *model runs* using similar initial conditions. The initial conditions are varied slightly for each run to mimic randomness within the earth system. \n",
    "\n",
    "1. Initialise any arrays\n",
    "\n",
    "2. Create a for loop which loops through the files in the ensemble foler and loads each sst file and the variables\n",
    "\n",
    "3. Within the for loop calculate the baseline, current climates and anomalies for each of the files\n",
    "uses formulas from last week \n",
    "\n",
    "4. For each type of climate: baselines, currents and anomalies, concatenate the arrays so you end up with three arrays of shape (200,36,72) (as you have 200 files, you will have 200 values for each grid point) \n",
    "data2 = pd.concat([year, anomaly], axis=1) # learned to concatenate two series into a df\n",
    "\n",
    "5. outside of the for loop calculate the anomaly mean (for each grid point)\n",
    "\n",
    "\n",
    "\n",
    "6. Now loop through all of the grid points and compare the distributions of the baseline compared to the currents - are they significantly different (i.e. is the global sst now significantly different from what it was during the baseline?)\n",
    "\n",
    "\n",
    "You should output:\n",
    "\n",
    "* an anomaly array of shape (36,72) which represents current - baseline SST\n",
    "* a boolean array of shape (36,72) which represents whether there is a statistical significant difference between baseline and current\n",
    "So this is not straightforward, if you're finding it impossible then just use the answers for this bit and try to understand what each line is doing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "from netCDF4 import Dataset,num2date\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Initialise any arrays** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((36,72))\n",
    "li = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create a for loop which loops through the files in the ensemble folder and loads each sst file and the variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4988615deb28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswta_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mswta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswta_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mswta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# li.append(swta[0,0,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = '/Users/bendixon/Documents/HadSST/'\n",
    "os.chdir('/Users/bendixon/Documents/HadSST/') \n",
    "for filename in os.listdir(directory):\n",
    "    swta_file = Dataset(filename) # fixed error by changing working directory\n",
    "    variables = swta_file.variables\n",
    "    swta = swta_file.variables['tos'][:]\n",
    "    li.append(swta[0,0,0])\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the action here is to use a loop to fill in an array\n",
    "# could try this out by making a loop to fill another array\n",
    "a = np.zeros((4,20))\n",
    "for i in range(1,20):\n",
    "    a[0,i] = 5 # this works! could also use .insert?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Within the for loop calculate the baseline, current climates and anomalies for each of the files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the sst file\n",
    "fn = '/Users/bendixon/Documents/HadSST/HadSST.4.0.0.0_ensemble_member_1.nc'\n",
    "swta_file = Dataset(fn)\n",
    "variables = swta_file.variables\n",
    "swta = swta_file.variables['tos'][:]\n",
    "time = swta_file.variables['time'][:]\n",
    "latitude = swta_file.variables['latitude'][:]\n",
    "longitude = swta_file.variables['longitude'][:]\n",
    "swta = np.ma.masked_values(swta, 9.969209968386869e+36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_units = swta_file.variables['time'].units\n",
    "calendar = swta_file.variables['time'].calendar\n",
    "time_convert = num2date(time, time_units, calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatetimeGregorian(1850, 2, 15, 0, 0, 0, 0)\n",
    "# np.where(time_convert == DateTime?)\n",
    "# date(1850,1,16).toordinal() - this gives the day number, but we want the number of the row in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980-01-16 12:00:00\n",
      "1950-01-16 12:00:00\n",
      "2000-01-16 12:00:00\n",
      "2018-12-16 12:00:00\n"
     ]
    }
   ],
   "source": [
    "print(time_convert[1200])\n",
    "print(time_convert[1560]) # not sure why some months there are measurements at 00:00 or 12:00\n",
    "print(time_convert[1800])\n",
    "print(time_convert[2027]) # this is only up to 2018, but that's the size of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_1950 = 1200; i_1980 = 1569; i_2000 = 1800; i_2018 = 2027\n",
    "\n",
    "baseline = swta[i_1950:i_1980,:,:]\n",
    "baseline = np.mean(baseline,axis=0) \n",
    "\n",
    "current = swta[i_2000:i_2018,:,:]\n",
    "current = np.mean(current,axis=0)\n",
    "\n",
    "# current - baseline\n",
    "anomaly = current - baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workings/ideas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall process:\n",
    "1. Create an array\n",
    "2. Loop through each file and find the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initialise empty arrays\n",
    "\n",
    "# open data in for loop\n",
    "for i in range(1,200):\n",
    "\n",
    "    # calculate baseline and current global mean sst\n",
    "    \n",
    "    # you can't np.concatenate to an empty array so create an if statement to deal with the first instance    \n",
    "\n",
    "\n",
    "# calculate ensemble mean sst anomaly for each grid point\n",
    "\n",
    "# loop through each grid point and assess whether the current values are significantly different from the baseline\n",
    "for i in range(36):\n",
    "    for j in range(72):\n",
    "        # ...     \n",
    "\n",
    "anomaly = \n",
    "significance ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workings - experimenting with .insert to populate the array\n",
    "b = [1,1,1,1]\n",
    "for i in range(len(b)):\n",
    "    b.insert(99999,5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current working directory\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
